{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8357d1f4",
   "metadata": {},
   "source": [
    "# AI Training For Fertilizer v.s Tap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef33894b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import KFold\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab6206c",
   "metadata": {},
   "source": [
    "## Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c569a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLayer(nn.Module):\n",
    "    def __init__(self, inputChannels, outputChannels):\n",
    "        super().__init__()\n",
    "        self.ConvLayer = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=inputChannels, out_channels=outputChannels, kernel_size=3, padding=1, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, padding=1, stride=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        return self.ConvLayer(x)\n",
    "\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    \n",
    "    \n",
    "    def __init__(self, in_channels: int, hidden_channels: int, hidden_layers:int, out_channels: int, height: int, width: int):\n",
    "        super().__init__()\n",
    "        \n",
    "        num = (height/(hidden_layers*2))*(width/(hidden_layers*2))\n",
    "\n",
    "        self.input = nn.Conv2d(in_channels=in_channels, out_channels=hidden_channels, kernel_size=3, padding=1, stride=1)\n",
    "        self.conv_layers = nn.ModuleList()\n",
    "        self.output = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.LazyLinear(out_features=out_channels),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        for i in range(hidden_layers):\n",
    "            self.conv_layers.append(ConvLayer(inputChannels=hidden_channels, outputChannels=hidden_channels))\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, X: torch.Tensor):\n",
    "        X = self.input(X)\n",
    "\n",
    "        for layer in self.conv_layers:\n",
    "            X = layer(X)\n",
    "\n",
    "        return self.output(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64622319",
   "metadata": {},
   "source": [
    "## Loading Data and Transforming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad354829",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.Resize(size=(640,480)), transforms.ColorJitter(brightness=.5, contrast=.5, saturation=.5), transforms.RandomRotation(degrees=(0,360)), transforms.ToTensor()])\n",
    "\n",
    "dataset = datasets.ImageFolder(root=\"data\", transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b8e1e3",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d004c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print( torch.cuda.is_available())\n",
    "BATCH_SIZE=16\n",
    "LEARNING_RATE=0.001\n",
    "NUM_WORKERS=4\n",
    "EPOCHS = 10\n",
    "MODEL_NAME = \"First Trial\"\n",
    "\n",
    "#Create Schedularer\n",
    "\n",
    "model = Model(in_channels=3, hidden_channels=10, hidden_layers=3, out_channels=3, height=480, width=640)\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(lr=LEARNING_RATE, params=model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a73f4d",
   "metadata": {},
   "source": [
    "## Accuracy Function and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1a6524",
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc(preds, y):\n",
    "    preds=torch.argmax(preds, dim=1)\n",
    "    correct = torch.eq(y, preds).sum().item()\n",
    "    acc = (correct / len(preds)) * 100\n",
    "    return acc\n",
    "\n",
    "def plot_loss(num_of_epochs, vals, title, y_axis):\n",
    "    epoch_list = range(num_of_epochs)\n",
    "    for i in vals:\n",
    "        plt.plot(epoch_list, i)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel(y_axis)\n",
    "    plt.title(title)\n",
    "    plt.savefig(f\"{title}.png\")\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3638c7b",
   "metadata": {},
   "source": [
    "## Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc3e3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold= KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "global_training_loss, global_training_acc, global_val_loss, global_val_acc =[],[],[],[]\n",
    "\n",
    "\n",
    "model.to(device=DEVICE)\n",
    "print(f\"\\nTraining started on {DEVICE}\\n\")\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kfold.split(dataset)):\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    training_loss, val_loss, training_acc, val_acc = 0,0,0,0\n",
    "    training_loss_vals, training_acc_vals, val_loss_vals, val_acc_vals = [], [], [], []\n",
    "    \n",
    "    training_set = Subset(dataset, train_idx)\n",
    "    val_set = Subset(dataset, val_idx)\n",
    "\n",
    "    train_loader = DataLoader(dataset=training_set, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, shuffle=True)\n",
    "    val_loader = DataLoader(dataset=val_set, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, shuffle=False)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in (range(EPOCHS)):\n",
    "        for X, y in tqdm(train_loader, leave=True):\n",
    "            X, y = X.to(device=DEVICE), y.to(device=DEVICE)\n",
    "            preds = model(X)\n",
    "            #preds=preds.argmax(dim=1)\n",
    "            #preds = preds.to(torch.uint8)\n",
    "            #print(preds)\n",
    "            loss = loss_function(preds, y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            training_loss+=loss.item()\n",
    "            training_acc+=acc(preds=preds, y=y)\n",
    "\n",
    "\n",
    "        training_loss /= len(train_loader)\n",
    "        training_acc /= len(train_loader)\n",
    "\n",
    "        training_loss_vals.append(training_loss)\n",
    "        training_acc_vals.append(training_acc)\n",
    "    \n",
    "        with torch.inference_mode():\n",
    "            model.eval()\n",
    "            for X, y in val_loader:\n",
    "                X, y = X.to(device=DEVICE), y.to(device=DEVICE)\n",
    "                preds = model(X)\n",
    "                loss = loss_function(preds, y)\n",
    "                val_loss+=loss.item()\n",
    "                val_acc+=acc(preds=preds, y=y)\n",
    "\n",
    "            val_loss /= len(val_loader)\n",
    "            val_acc /= len(val_loader)\n",
    "\n",
    "            val_loss_vals.append(val_loss)\n",
    "            val_acc_vals.append(val_acc)\n",
    "\n",
    "        print(f\"\\nEpoch {epoch} finished with training loss: {training_loss}, testing loss: {val_loss}, training accuracy: {training_acc}, testing accuracy: {val_acc}\\n\")\n",
    "    \n",
    "    plot_loss(num_of_epochs=EPOCHS, vals=training_loss_vals, y_axis=\"Loss\", title=f\"Fold #{fold} Training Loss\")\n",
    "    plot_loss(num_of_epochs=EPOCHS, vals=training_acc_vals, y_axis=\"Accuracy\", title=f\"Fold #{fold} Training Accuracy\")\n",
    "    plot_loss(num_of_epochs=EPOCHS, vals=val_loss_vals, y_axis=\"Loss\", title=f\"Fold #{fold} Validation Loss\")\n",
    "    plot_loss(num_of_epochs=EPOCHS, vals=val_acc_vals, y_axis=\"Accuracy\", title=f\"Fold #{fold} Validation Loss\")\n",
    "\n",
    "    global_training_loss.append(training_loss)\n",
    "    global_training_acc.append(training_acc)\n",
    "    global_val_loss.append(val_loss)\n",
    "    global_val_acc.append(val_acc)\n",
    "    \n",
    "    print(f\"Fold #{fold} Completed\")\n",
    "\n",
    "print(f\"Global Training Losses = {global_training_loss}\\nGlobal Training Accuracy = {global_training_acc}\\nGlobal Validation Loss = {global_val_loss}\\nGlobal Validation Accuracy = {global_val_acc}\")\n",
    "torch.save(obj=model.state_dict(), f=MODEL_NAME)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6232f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "img = Image.open(\"data/clean/Clean Tap 2_image_0.png\")\n",
    "    \n",
    "tran = transforms.Compose([transforms.Resize((640,480)), transforms.ToTensor()])\n",
    "\n",
    "img = tran(img).to(device=DEVICE)\n",
    "img = torch.unsqueeze(img, dim=0)\n",
    "preds = model(img)\n",
    "\n",
    "preds = torch.nn.functional.softmax(preds, dim = 1)#logits to preds\n",
    "labels = torch.argmax(preds, dim=1).item()\n",
    "print(preds)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe839920",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "preds_list = []\n",
    "labels_list = []\n",
    "with torch.no_grad():\n",
    "    for X, y in tqdm(val_loader): #Last Fold\n",
    "        X, y = X.to(device=DEVICE), y.to(device=DEVICE)\n",
    "        preds = model(X)\n",
    "        _, preds = torch.max(preds, 1)\n",
    "\n",
    "        preds_list.extend(preds.cpu().numpy())\n",
    "        labels_list.extend(y.cpu().numpy())\n",
    "\n",
    "cm = confusion_matrix(labels_list, preds_list, labels=[0,1,2])\n",
    "display = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Clean\", \"Dirty\", \"Empty\"])\n",
    "display.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
